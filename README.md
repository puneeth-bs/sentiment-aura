# Sentiment Aura â€” Real-Time Emotional Visualization

> A real-time voice-to-emotion visualizer that listens to your speech, transcribes it live, analyzes its sentiment, and visualizes your emotions through a glowing, dynamic *Perlin noise aura* on screen.

---

## âœ¨ Overview

**Sentiment Aura** connects your **voice**, **language**, and **emotion** in real time.  
It uses:

- ğŸ™ï¸ **Deepgram** â€” real-time speech-to-text transcription  
- ğŸ§  **OpenAI API** â€” semantic sentiment analysis  
- ğŸŒ€ **p5.js** â€” dynamic particle-based emotional aura visualization  
- âš™ï¸ **FastAPI** â€” backend orchestration  
- âš›ï¸ **React** â€” interactive frontend UI  

---

## âš™ï¸ How to Run the Project Locally

This section explains how to install and run both the **backend (FastAPI)** and **frontend (React + p5.js)**.


### 1. Clone the Repository

```bash
git clone https://github.com/<your-username>/sentiment-aura.git
cd sentiment-aura
```

### 2. Setup and Run the Backend (FastAPI)

#### Create a Virtual Environment
```bash
cd server
python3 -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

#### ğŸ“¦ Install Dependencies
```bash
pip install -r requirements.txt
```

#### âš™ï¸ Create .env File

Create a .env file inside the backend/ folder with the following content:
```bash
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=your_openai_model
```

#### â–¶ï¸ Start the Backend Server
```bash
uvicorn main:app --reload
```
This will start your FastAPI server on http://localhost:8000

### 3. Setup and Run the Frontend (React)

#### ğŸ“¦ Install Node Dependencies
```bash
cd client
npm install
```

#### âš™ï¸ Create .env File

Create a .env file inside the frontend/ folder with the following content:
```bash
REACT_APP_DEEPGRAM_API_KEY=your_deepgram_api_key
REACT_APP_BACKEND_URL=http://localhost:8000
```

#### â–¶ï¸ Start the Frontend Server
```bash
npm start
```
This runs the app on http://localhost:3000

### ğŸ”— 4. Verify Connection

Open http://localhost:3000

Click Start â€” you should see:

The â€œListeningâ€¦â€ pulse animation

Your voice transcribed into live text

The aura background reacting to your tone

When you stop speaking, the transcript is sent to the backend â†’ analyzed â†’ and aura color changes dynamically.


| Issue                        | Cause                            | Fix                                                |
| ---------------------------- | -------------------------------- | -------------------------------------------------- |
| âŒ `OPENAI_API_KEY not found` | `.env` missing                   | Add your API key in backend `.env`                 |
| âš ï¸ `BACKEND_URL undefined`  | Missing frontend `.env` variable | Add `REACT_APP_BACKEND_URL=http://localhost:8000` |
| ğŸ’¤ UI lag or freezes         | Too many rerenders               | Refresh or lower particle count in `AuraCanvas.js` |
| ğŸ¤ Mic not working           | Browser permission denied        | Allow mic access in browser settings               |



## ğŸ§© Architecture Diagram

The system connects **speech**, **AI sentiment analysis**, and **visual art** in real time.  
Hereâ€™s how everything interacts:

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         ğŸ™ï¸ User          â”‚
                    â”‚   Speaks through mic     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚     Deepgram JavaScript SDK â”‚
                   â”‚  (Streaming Speech-to-Text) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  Live transcript JSON
                                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                     React Frontend                   â”‚
      â”‚------------------------------------------------------â”‚
      â”‚                                                      â”‚
      â”‚  ğŸ§  useDeepgramStream.js                              â”‚
      â”‚    â€¢ Captures mic audio via MediaRecorder            â”‚
      â”‚    â€¢ Streams chunks to Deepgram SDK                  â”‚
      â”‚    â€¢ Updates transcript in real-time                 â”‚
      â”‚    â€¢ Calls sentiment API when transcript is final    â”‚
      â”‚                                                      â”‚
      â”‚  ğŸ¨ SpeechAura.js                                   â”‚
      â”‚    â€¢ Displays live transcript                        â”‚
      â”‚    â€¢ Shows â€œListeningâ€¦â€ pulse while recording        â”‚
      â”‚    â€¢ Passes sentiment to AuraCanvas                  â”‚
      â”‚                                                      â”‚
      â”‚  ğŸŒˆ AuraCanvas.js (p5.js)                            â”‚
      â”‚    â€¢ Renders Perlin-noise particles                  â”‚
      â”‚    â€¢ Smoothly transitions color based on sentiment   â”‚
      â”‚    â€¢ Creates ambient wavy glow                       â”‚
      â”‚                                                      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                POST /api/v1/process_text
                             â”‚
                             â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚           FastAPI Backend       â”‚
           â”‚---------------------------------â”‚
           â”‚  /api/v1/process_text           â”‚
           â”‚     â†’ Receives transcript       â”‚
           â”‚     â†’ Calls analyze() in LLM    â”‚
           â”‚                                 â”‚
           â”‚  services/llm.py                â”‚
           â”‚     â†’ Sends text to OpenAI      â”‚
           â”‚     â†’ Gets sentiment JSON       â”‚
           â”‚     â†’ Returns label & score     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚         OpenAI GPT Model        â”‚
             â”‚---------------------------------â”‚
             â”‚  â€¢ Analyzes tone of text        â”‚
             â”‚  â€¢ Returns structured JSON:     â”‚
             â”‚    { sentiment_label, score }   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚      React (Frontend Visualization)       â”‚
           â”‚-------------------------------------------â”‚
           â”‚  â€¢ Updates sentimentRef in SpeechAura     â”‚
           â”‚  â€¢ AuraCanvas transitions color           â”‚
           â”‚  â€¢ Text fades in/out dynamically          â”‚
           â”‚  â€¢ Final aura visual = Emotion feedback   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




---

### ğŸ§  Data Flow Summary

| Step | Component | Description |
|------|------------|-------------|
| 1ï¸âƒ£ | **Microphone** | Captures live audio from user |
| 2ï¸âƒ£ | **Deepgram SDK** | Streams real-time audio â†’ transcript |
| 3ï¸âƒ£ | **React Hook (`useDeepgramStream`)** | Updates transcript & triggers sentiment |
| 4ï¸âƒ£ | **FastAPI Backend** | Receives transcript, calls OpenAI |
| 5ï¸âƒ£ | **OpenAI API** | Returns structured sentiment JSON |
| 6ï¸âƒ£ | **SpeechAura + AuraCanvas** | Visualizes emotions with color and flow |
| 7ï¸âƒ£ | **User UI** | Sees glowing aura that changes dynamically |

---
